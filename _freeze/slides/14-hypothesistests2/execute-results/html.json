{
  "hash": "a9b663b8d69843723831663504442b5d",
  "result": {
    "markdown": "---\ntitle: \"Hypothesis tests pt 2\"\nsubtitle: \"Lecture 14\"\ndate: \"June 12, 2023\"\nformat: revealjs\nsmaller: true\n---\n\n\n\n\n## Logistics {.smaller}\n\n-   Project component 3, results: draft by Thursday (June 15), submit for grading next Tuesday (June 20)\n\n    -   Drafts should be complete--meaning you attempted all parts\n\n## Today {.smaller}\n\n-   Hypothesis tests in more specifics\n\n## Hypothesis test process\n\n::: incremental\n-   Define your null hypothesis (boring result; nothing is happening; no group differences) and an alternative hypothesis (the other possibility)\n\n-   In the world where your null hypothesis is true, would your sample be super weird? Run a test to find out!\n\n    -   Figure out what statistical test you need to run. This depends on the types of your variables.\n    -   Run the test\n    -   Interpret the p value the test gives you. This tells you whether your sample falls far enough outside the expected distribution.\n\n-   If the sample is sufficiently different than we expected, we reject the null hypothesis in favor of the alternative hypothesis\n\n-   If not, we fail to reject the null hypothesis\n\n    -   \"Fail\" sounds harsh, but this is normal and fine! We do analysis to find out if our predictions are true--sometimes they aren't and that's valuable information.\n:::\n\n## Conditions for hypothesis tests\n\n-   Sampling distributions follow predictable shapes (and so hypothesis tests \"work\") when two conditions are met:\n\n::: incremental\n-   *Independence:* The value of one observation in the sample does not depend on the values of any of the others.\n\n    -   Random sampling of individuals guarantees independence\n    -   So does random assignment to experimental conditions\n    -   Example that is *not* independent: I am interested in relationship satisfaction in monogamous relationships. I sample couples and ask both partners in each couple how satisfied they are.\n    -   One partner's satisfaction is surely related to the other's!\n\n-   *Samples are large enough:* Big samples are more likely to generate normal sampling distributions.\n\n    -   How large is large enough depends on the specific test\n:::\n\n# How do I know if my sample is weird?\n\n## General hypothesis test logic\n\n-   Would the sample fall within the distribution of the samples you would get under the null hypothesis (the *null distribution*)?\n\n![](images/13/clt_n20_newsample.png)\n\n# Understanding distributions: with the normal distribution as an example\n\n## Distributions {.smaller}\n\n-   Null distributions take different shapes depending on what test statistic you calculate\n\n    -   Which in turn depends on the combination of categorical and numeric variables you have---different tests (and so test statistics) are appropriate for different kinds of variables\n\n-   But one very common one is the normal distribution\n\n    -   Bell-shaped; defined by a mean and a standard deviation\n\n## Z scores\n\n::: incremental\n-   Z scores are a measure of how far an observation is from the center of a normal distribution, in units of standard deviation (or standard error--more on the difference in a moment).\n\n-   Z scores are the test statistic for the normal distribution\n\n-   Why are standard units important? For comparing across distributions.\n\n    -   A Z score of -1 means the same thing in every normal distribution: the observation is one standard deviation below the mean.\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## Standard deviation vs standard error {.smaller}\n\n::: incremental\n-   Normal distributions can describe either individual samples or the distribution of sample statistics between samples---we'll do both here.\n-   The logic is exactly the same, but the name for the measure of distribution spread varies slightly.\n-   **Standard deviation**: measures variation within a single sample\n-   **Standard error**: measures variation in a sample statistic between multiple samples.\n:::\n\n## Standard deviation vs standard error\n\n::: columns\n::: {.column width=\"30%\"}\n-   Example: Scores on the (pre-2016) SAT were normally distributed with a mean of 1500 points and a standard deviation of 300 points.\n\n    -   That distribution describes the scores of individual students who take the SAT\n    -   So standard *deviation* is the term we use to describe its spread\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## Standard deviation vs standard error\n\n::: columns\n::: {.column width=\"30%\"}\n::: incremental\n-   Now imagine that we randomly sampled students and asked them to provide their SAT scores. We have many samples of 25 students each.\n\n-   The mean score in each 25-student sample is our sample statistic\n\n-   The term for the spread of this sampling distribution is the standard error.\n\n-   It is determined by formulas that vary depending on the specific situation. You generally won't calculate it yourself; it will be provided in R output.\n\n-   Standard error is always smaller than standard deviation: there is more variation within samples from the same population than between them.\n:::\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## Percentiles\n\n-   Percentile: What percent of the data is below a particular observation.\n\n-   From 0% to 100%, but generally reported as a proportion instead (0-1).\n\n-   Something that can be calculated with software (like R)\n\n    -   The `pnorm()` function takes a Z score and gives you the corresponding percentile\n\n![](images/13/nel_percentile.png)\n\n## Percentiles {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 1) # q is the Z score (yes, it's confusing). \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8413447\n```\n:::\n\n```{.r .cell-code}\n# Nel's Z score is 1 because their SAT score is 1 standard \n# deviation above the mean for all test-takers.\n```\n:::\n\n\n. . .\n\n-   Conclusion: 84% of SAT-takers score below Nel.\n\n## Z scores and percentiles\n\n-   68% of observations are within 1 standard error/standard deviation of the mean\n-   95% are within 2 standard errors/standard deviations\n-   99.7% are within 3 standard errors/standard deviations\n\n![](images/13/percentiles.png)\n\n## Z scores, percentiles, and p values: example\n\n-   Heights of US adults who identify as men follow a normal distribution. Mean = 70 inches; standard deviation = 3.3 inches.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n## Z scores: exercise Q1\n\n::: incremental\n-   What is the Z score of a man who is 70 inches tall?\n\n    -   Zero!\n    -   70 is the mean of this distribution. An observation whose value is exactly equal to the mean has a Z score of 0.\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n## Z scores: exercise Q2\n\n-   What is the Z score of a man who is 65 inches tall?\n\n    -   \n\n        a.  About 1.3\n\n    -   \n\n        b.  About -3\n\n    -   \n\n        c.  About -1.5\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Z scores: exercise Q2\n\n-   \n\n    c.  About -1.5\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n## Percentiles: exercise Q3\n\n-   If someone is in the 30th percentile in terms of height, is their height most likely:\n\n    -   \n\n        a.  About 68 inches\n\n    -   \n\n        b.  About 72 inches\n\n    -   \n\n        c.  About 62 inches\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Percentiles: exercise Q3\n\n-   \n\n    a.  About 68 inches\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n## P values\n\n::: incremental\n-   Percentiles/Z scores quantify how far our sample is from what we expected under the null hypothesis\n\n-   P value: closely related to percentile. How much of the expected distribution under the null hypothesis has a value more extreme than what we find in our sample?\n\n    -   In other words: If the null hypothesis were true, what would the probability be of getting a sample as or more extreme than what was actually observed?\n:::\n\n## One-tailed vs two-tailed tests\n\n::: incremental\n-   How we think about p values depends on if our hypothesis test is *one-tailed* or *two-tailed*.\n\n-   One-tailed: we reject the null hypothesis only if our alternative hypothesis is specific about the *direction* of difference.\n\n    -   New Yorkers sleep less than people in other cities.\n    -   The average number of friends for people who live in rural areas of the US has increased over the past 50 years\n\n-   Two-tailed: we reject the null hypothesis if direction is not important: ie, if the sample statistic is either significantly bigger *or* significantly smaller than we expect.\n\n    -   New Yorkers sleep a different amount than people in other cities\n    -   The average number of friends for people who live in rural areas of the US has changed over the past 50 years.\n\n-   Most hypothesis tests involving normal distributions in sociology are two-tailed, and most software defaults to two-tailed tests.\n\n-   When using some other distributions, like Chi square distributions, tests are always one-tailed---more on that another day.\n:::\n\n## One-tailed p values\n\n-   The p value for a one-tailed test is the percent of the distribution that is either bigger or smaller than the observed value (depending on which direction the hypothesis takes).\n\n-   Example: If you randomly select an American who identifies as a man, what is the probability his height will be 63.4 inches or less? (recall the height distribution: mean 70 inches, standard deviation 3.3 inches)\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## One-tailed p values {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = -2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02275013\n```\n:::\n:::\n\n\n. . .\n\n-   In this case, p value and percentile are the same!\n\n## One-tailed p values\n\n-   What is the probability of randomly selecting an American man who is 76.6 inches tall or taller? (use the same height distribution)\n\n-   First: Draw the distribution and shade the area we are interested in.\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n## One tailed p values\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n-   What is the p value here?\n-   Is it the same as the percentile?\n\n## Two-tailed p values\n\n-   The p value for a two-tailed test is the probability that you would have drawn a sample equal to or more extreme than the one you have, in either direction.\n-   We count something as \"more extreme\" if it is larger in *absolute* Z score.\n\n## Two-tailed p values\n\n-   Example: What is the probability of randomly selecting an American man whose height is two or more standard deviations from the mean?\n\n    -   In other words: the probability of randomly selecting a man who is either 63.4 inches or shorter OR 76.6 inches or taller\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14-hypothesistests2_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n## P values and statistical significance\n\n::: incremental\n-   Back to our question from earlier: how do I know if my sample is weird enough to warrant rejecting my null hypothesis?\n\n-   We define threshold p values before we run tests\n\n-   If the p value we get is smaller than the threshold, we say the sample provides *statistically significant* evidence against the null hypothesis, and we reject it.\n\n-   Most common cutoff, by (arbitrary but common) convention: p = 0.05\n\n    -   So, if we get a p value for our sample smaller than 0.05--meaning that there was a less than five percent chance that we would have obtained our result if the null was true--we reject the null.\n:::\n\n# Hypothesis tests for different variable types\n\n## Hypothesis test process\n\n-   Define your null hypothesis (boring result; nothing is happening; no group differences) and an alternative hypothesis (the other possibility)\n\n-   In the world where your null hypothesis is true, would your sample be super weird? Run a test to find out!\n\n    -   Figure out what statistical test you need to run. This depends on the types of your variables.\n    -   Run the test\n    -   Interpret the p value the test gives you. This tells you whether your sample falls far enough outside the expected distribution.\n\n-   If the sample is sufficiently different than we expected, we reject the null hypothesis in favor of the alternative hypothesis\n\n-   If not, we fail to reject the null hypothesis\n\n## Different types of tests\n\n::: incremental\n-   Now that we know a little bit about distributions, how do we run tests on data?\n\n-   Step 1: Figure out what kind of test you need\n\n    -   This depends on your variable types. Are they...\n\n        -   Categorical with two categories (including binary variables)?\n        -   Categorical with three or more categories?\n        -   Numeric?\n        -   *Wait, what about ordinal?* Ordinal variables are tricky. For our purposes, you can choose to treat them as either numeric or nominal categorical variables instead.\n\n    -   It also depends on how many variables your question involves\n\n        -   Two? (one explanatory variable; one response variable)\n        -   Or more than two? (more than one explanatory variable; one response variable)\n\n    -   Does this feel similar to plotting? Lots of things depend on what kind of variables you have!\n:::\n\n## Different types of tests: An overview\n\n-   Which test to use is not as cut-and-dry as you might hope---there is overlap in use cases. This is my recommendation for this class.\n-   These terms won't mean much to you right now. We'll come back to the specifics.\n\n![](images/14/test_table.png)\n\n## Identifying the right test: exercise Q4\n\n-   For each of these research questions, identify the explanatory variable, the response variable, their types, and the correct statistical test. *Think about what the data would look like for each individual in these cases*\n\n-   \n\n    a.  How does whether a student attended a public or private school affect their chances of graduating high school?\n\n-   \n\n    b.  How do outcomes of traffic stops (warnings, citations, or arrests) vary by the race of the driver?\n\n-   \n\n    c.  How does the probability a doctor refers a patient to a specialist vary by the patient's body mass index?\n\n-   \n\n    d.  How is a country's average life expectancy related to the amount of money per person it spends on health care?\n\n![](images/14/test_table.png)\n\n## Running a hypothesis test in R with `infer`\n\n::: incremental\n-   The bad news: there are a lot of different tests.\n\n-   The good news: regardless of what specific test you run, the logic is similar, and your code will look about the same!\n\n-   We will be using [the `infer` package](https://infer.tidymodels.org/index.html) to conduct hypothesis tests\n\n    -   `infer` is built to work on similar logic to the tidyverse---where `filter()`, `mutate()`, and `ggplot()` are from\n    -   Its documentation is excellent---check out the website ([link here](https://infer.tidymodels.org/index.html)) if you ever get stuck\n:::\n",
    "supporting": [
      "14-hypothesistests2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}